{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classifier_resnet101",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GiVGN4uYm6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3HFAR-6sWqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKxRrwftgJIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import utils\n",
        "\n",
        "from PIL import Image, ImageDraw\n",
        "from engine import train_one_epoch\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "from tqdm import tqdm\n",
        "\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "\n",
        "import time\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2G7H6HBWyXTc",
        "colab_type": "text"
      },
      "source": [
        "##DATA "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APSijYIKG_CF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define data and model directories\n",
        "data_dir = '/content/drive/My Drive/DATA_DIR/'\n",
        "model_dir = '/content/drive/My Drive/Full_Data/ResNet101_v1/classification_model_resnet101.pt'\n",
        "save_folder = '/content/drive/My Drive/Full_Data/ResNet101_v1/'\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 2\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 8\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 20\n",
        "\n",
        "#input size of images going into model\n",
        "input_size = 800\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "# when True we only update the reshaped layer params\n",
        "feature_extract = False\n",
        "\n",
        "#number of samples used to train and test network, use 'all' for full data set\n",
        "train_image_samples = 'all'\n",
        "dev_image_samples = 'all'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saPXzqOWsD9V",
        "colab_type": "text"
      },
      "source": [
        "#TENSORBOARD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dc1FviKVtjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Gu4bxs6VxmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# define place to hold data\n",
        "writer = SummaryWriter(save_folder + 'runs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMkpZe0qoQ2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorboard --logdir=drive/My\\ Drive/Full_Data/Ben_ResNet101_v1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6wLxsU5jAiU",
        "colab_type": "text"
      },
      "source": [
        "#BUILD DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brP-WonZhtIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_tr = pd.read_csv(data_dir + 'train.csv', na_filter=False)\n",
        "labels_dev = pd.read_csv(data_dir + 'dev.csv', na_filter=False)\n",
        "\n",
        "if train_image_samples != 'all':\n",
        "  labels_tr = labels_tr.sample(n=train_image_samples).sort_values(by = 'image_name')\n",
        "if dev_image_samples != 'all':\n",
        "  labels_dev = labels_dev.sample(n=dev_image_samples).sort_values(by = 'image_name')\n",
        "\n",
        "img_class_dict_tr = dict(zip(labels_tr.image_name, labels_tr.annotation))\n",
        "img_class_dict_dev = dict(zip(labels_dev.image_name, labels_dev.annotation))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu809qhciuAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ForeignObjectDataset(object):\n",
        "    \n",
        "    def __init__(self, datafolder, datatype='train', transform = True, labels_dict={}):\n",
        "        self.datafolder = datafolder\n",
        "        self.datatype = datatype\n",
        "        self.labels_dict = labels_dict\n",
        "        self.image_files_list = [s for s in sorted(os.listdir(datafolder)) if s in labels_dict.keys()]\n",
        "        self.transform = transform\n",
        "        self.annotations = [labels_dict[i] for i in self.image_files_list]\n",
        "            \n",
        "    def __getitem__(self, idx):\n",
        "        # load images \n",
        "        img_name = self.image_files_list[idx]\n",
        "        img_path = os.path.join(self.datafolder, img_name)\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        width, height = img.size[0],img.size[1]  \n",
        "        \n",
        "        if self.datatype == 'train':\n",
        "            \n",
        "            if self.labels_dict[img_name] == '':\n",
        "                label = 0\n",
        "            else:\n",
        "                label = 1\n",
        "\n",
        "            if self.transform is not None:\n",
        "                img = self.transform(img)\n",
        "                \n",
        "            return img, label\n",
        "        \n",
        "        if self.datatype == 'dev':\n",
        "            \n",
        "            if self.labels_dict[img_name] == '':\n",
        "                label = 0\n",
        "            else:\n",
        "                label = 1\n",
        "            \n",
        "            if self.transform is not None:\n",
        "                img = self.transform(img)\n",
        "\n",
        "            return img, label\n",
        "\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRUCNfWMizIT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.Resize((input_size,input_size)),\n",
        "        transforms.ColorJitter(brightness=(0.85,1.05)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((input_size,input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "print(\"Initializing Datasets and Dataloaders...\")\n",
        "\n",
        "dataset_train = ForeignObjectDataset(datafolder= data_dir + 'train/', datatype='train', transform=data_transforms['train'], labels_dict=img_class_dict_tr)\n",
        "dataset_dev = ForeignObjectDataset(datafolder= data_dir + 'dev/', datatype='dev', transform=data_transforms['val'], labels_dict=img_class_dict_dev)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HZCahkWi2xo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_loader = torch.utils.data.DataLoader(\n",
        "    dataset_train, batch_size=8, shuffle= True, num_workers=4,\n",
        "    collate_fn=utils.collate_fn)\n",
        "\n",
        "data_loader_val = torch.utils.data.DataLoader(\n",
        "    dataset_dev, batch_size=1, shuffle= False, num_workers=4,\n",
        "    collate_fn=utils.collate_fn)\n",
        "\n",
        "# Create training and validation dataloaders\n",
        "dataloaders_dict = {'train': data_loader, 'val': data_loader_val}\n",
        "\n",
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0ESZxWIDxDk",
        "colab_type": "text"
      },
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XbtU5e9zZMSD",
        "colab": {}
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs):\n",
        "    since_start = time.time()\n",
        "    best_auc = 0.0\n",
        "    best_acc = 0.0\n",
        "    best_loss = 10.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        since_epoch = time.time()\n",
        "        \n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            preds_prob = torch.empty(0).to(device)\n",
        "            gt = torch.empty(0).to(device)\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                \n",
        "                inputs = torch.stack(inputs)\n",
        "                labels = list(labels)\n",
        "                labels = torch.LongTensor(labels)\n",
        "\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    outputs_prob = torch.nn.Softmax(dim = 1)(outputs)\n",
        "                    loss = criterion(outputs_prob, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs_prob, 1)\n",
        "                    \n",
        "                    preds_prob = torch.cat((preds_prob,outputs_prob[:,1]))\n",
        "                    gt_batch = labels.data.float()\n",
        "                    gt = torch.cat((gt,labels.data.float()))\n",
        "                   \n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            if phase =='train':\n",
        "                epoch_loss_tr = epoch_loss\n",
        "                epoch_acc_tr = epoch_acc\n",
        "                print('TRAIN Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
        "            else:\n",
        "                fpr, tpr, _ = roc_curve(gt.tolist(), preds_prob.tolist())\n",
        "                epoch_auc = auc(fpr, tpr) \n",
        "                print('VAL Loss: {:.4f} Acc: {:.4f} AUC: {:.4f}'.format(epoch_loss, epoch_acc, epoch_auc))\n",
        "\n",
        "            # Save the model if AUC is better, save best acc and losses as well\n",
        "            if phase == 'val' and epoch_auc > best_auc:\n",
        "                best_auc = epoch_auc\n",
        "                best_epoch = epoch\n",
        "                torch.save(model.state_dict(), model_dir)\n",
        "            elif phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_epoch_acc = epoch\n",
        "            elif phase == 'val' and epoch_loss < best_loss:\n",
        "                best_loss = epoch_loss\n",
        "                best_epoch_loss = epoch\n",
        "\n",
        "        #add losses into tensorboard\n",
        "        writer.add_scalars('Losses',{'Training':epoch_loss_tr,'Validation':epoch_loss}, epoch)\n",
        "        writer.add_scalars('Accuracy',{'Training':epoch_acc_tr,'Validation':epoch_acc}, epoch)\n",
        "        writer.add_scalars('AUC',{'Validation':epoch_auc}, epoch)\n",
        "        \n",
        "        #print time taken \n",
        "        time_epoch = time.time() - since_epoch\n",
        "        print('epoch training complete in {:.0f}m {:.0f}s'.format(time_epoch // 60, time_epoch % 60))\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since_start\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best LOSS: {:.4f} on epoch {:.0f}'.format(best_loss,best_epoch_loss))\n",
        "    print('Best ACC: {:.4f} on epoch {:.0f}'.format(best_acc,best_epoch_acc))\n",
        "    print('Best AUC: {:.4f} on epoch {:.0f}'.format(best_auc,best_epoch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T9jajGIfZMSW",
        "colab": {}
      },
      "source": [
        "def _get_model(num_classes,feature_extract):\n",
        "    model = models.resnet101(pretrained = True)\n",
        "    set_parameter_requires_grad(model, feature_extract)\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "    return model\n",
        "\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lbTbDANMZMSm",
        "colab": {}
      },
      "source": [
        "# Get and send the model to GPU\n",
        "model_ft = _get_model(num_classes,feature_extract)\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run.\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qyGhYXIwZMSt",
        "colab": {}
      },
      "source": [
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train and evaluate\n",
        "train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOpVsmRbvwr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = _get_model(num_classes,feature_extract)\n",
        "model.to(device)\n",
        "model.load_state_dict(torch.load(model_dir))\n",
        "\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "\n",
        "  preds_prob = []\n",
        "  labels = []\n",
        "  locs = []\n",
        "\n",
        "  for image, label in tqdm(dataloaders_dict['val']):\n",
        "      \n",
        "      image = torch.stack(image)\n",
        "      image = image.to(device)\n",
        "\n",
        "      labels.append(label[-1])\n",
        "      \n",
        "      outputs = model(image)\n",
        "      outputs = torch.nn.Softmax(dim = 1)(outputs)\n",
        "\n",
        "      preds_prob.append(outputs[0][1])\n",
        "\n",
        "preds_prob=torch.Tensor(preds_prob)\n",
        "preds_prob=preds_prob.tolist()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huE9D4oJ0VjH",
        "colab_type": "text"
      },
      "source": [
        "#CALCULATING AUC AND ACC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO4VZlqcj1X-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = []\n",
        "for i in range(len(preds_prob)):\n",
        "  if (preds_prob[i] >= .5):\n",
        "    pred.append(1)\n",
        "  else:\n",
        "    pred.append(0)\n",
        "\n",
        "gt = labels_dev.annotation.astype(bool).astype(float).values\n",
        "\n",
        "plt.plot(gt, preds_prob,'.', Color = [0,0,0,0.1])\n",
        "plt.ylim((0,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rdl76LfPj2oa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = (pred == gt).mean()\n",
        "fpr, tpr, _ = roc_curve(gt, preds_prob)\n",
        "roc_auc = auc(fpr, tpr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W8WEl3-j4B0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(\n",
        "    subplot_kw=dict(xlim=[0, 1], ylim=[0, 1], aspect='equal'),\n",
        "    figsize=(6, 6)\n",
        ")\n",
        "ax.plot(fpr, tpr, label=f'ACC: {acc:.03}\\nAUC: {roc_auc:.03}')\n",
        "_ = ax.legend(loc=\"lower right\")\n",
        "_ = ax.set_title('ROC curve')\n",
        "ax.grid(linestyle='dashed')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-osnUbfEmqTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cls_res = pd.DataFrame({'image_name': dataset_dev.image_files_list, 'prediction': preds_prob})\n",
        "cls_res.to_csv(save_folder + 'classification.csv', columns=['image_name', 'prediction'], sep=',', index=None)\n",
        "print('classification.csv generated.')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
